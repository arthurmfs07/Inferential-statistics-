{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c57aba41-d1bc-48b1-a692-6f533e98f93d",
   "metadata": {},
   "source": [
    "## Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2648e77b-62eb-46d5-a9bd-a5cf176d5760",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import psi, polygamma\n",
    "from scipy.stats import beta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9288039-5862-4fc3-8dd4-77ca17331ea2",
   "metadata": {},
   "source": [
    "## MÉTODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe6f2b1-0c21-44a6-bd92-128b286e0b39",
   "metadata": {},
   "source": [
    "### Newton_Raphson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "83221322-6dc0-47ec-8d68-fcc48b476b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(theta, x):\n",
    "    alpha = theta[0]\n",
    "    beta = theta[1]\n",
    "    n = len(x)\n",
    "\n",
    "    h1 = psi(alpha) - psi(alpha + beta) - (1/n)*sum(np.log(x))\n",
    "    h2 = psi(beta) - psi(alpha + beta) - (1/n)*sum(np.log(1-x))\n",
    "    return[h1,h2]\n",
    "\n",
    "def inv_Hessian(theta, x):\n",
    "    alpha = theta[0]\n",
    "    beta = theta[1]\n",
    "\n",
    "    # definir matriz\n",
    "    h11 = polygamma(1, alpha) - polygamma(1, alpha + beta)\n",
    "    h12 = -polygamma(1, alpha + beta)\n",
    "    h21 = -polygamma(1, alpha + beta)\n",
    "    h22 = polygamma(1, beta) - polygamma(1, alpha + beta)\n",
    "    H_inv = np.linalg.inv([[h11, h12],[h21, h22]])\n",
    "    return H_inv\n",
    "    \n",
    "def ML_beta(x, niter):\n",
    "    # chute inicial vetor theta0 = (alpha0, beta0)\n",
    "    theta0 = np.array([0.1, 0.1])\n",
    "    # criar lista para armazenar todos pares de estimativas de parâmetros\n",
    "    thetas = [theta0]\n",
    "\n",
    "    for k in range(1, niter+1):\n",
    "        theta_k = thetas[k-1] - np.dot( inv_Hessian(thetas[k-1],x), grad(thetas[k-1],x) )\n",
    "        thetas.append(theta_k)\n",
    "    return thetas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e308f0-8dfb-4511-9ec8-04390d87126f",
   "metadata": {},
   "source": [
    "### Rodando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7df212fe-6f9b-414a-8af7-655ce75aa8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(512)\n",
    "n = 1000\n",
    "N = 5000\n",
    "alpha_dist = 3\n",
    "beta_dist = 5\n",
    "\n",
    "sample_parameters = []\n",
    "\n",
    "for _ in range(N):\n",
    "    x = beta.rvs(alpha_dist, beta_dist, size=n)\n",
    "    estimated_parameters = ML_beta(x, niter=10)[-1] # Taking the last two estimated parameters from the 10 steps (10 different values of pair of alpha and beta from the method)\n",
    "    sample_parameters.append(estimated_parameters)\n",
    "\n",
    "# Display the estimated parameters\n",
    "#print(\"Estimated parameters for\", N, \"samples:\")\n",
    "#for i, params in enumerate(sample_parameters[:]): # Displaying parameters for the the : samples\n",
    "    #print(f\"Sample {i+1}: alpha={params[0]}, beta={params[1]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9c6fe17b-ed93-4c13-9280-ba66e1a9e4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007852477622572351\n",
      "0.01089015107255431\n",
      "0.016104817404162645\n",
      "0.0471181529039052\n"
     ]
    }
   ],
   "source": [
    "array1 = np.array(sample_parameters)  \n",
    "\n",
    "estimated_bias_alpha = np.mean(array1[:,0]) - alpha_dist\n",
    "estimated_bias_beta = np.mean(array1[:,1]) - beta_dist\n",
    "\n",
    "print(estimated_bias_alpha)\n",
    "print(estimated_bias_beta)\n",
    "\n",
    "\n",
    "estimated_eqm_alpha = np.mean( (array1[:,0] - alpha_dist)**2 )\n",
    "estimated_eqm_beta = np.mean( (array1[:,1] - beta_dist)**2 ) \n",
    "\n",
    "print(estimated_eqm_alpha)\n",
    "print(estimated_eqm_beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264b674d-ee06-4da3-adf9-5f0ac9e3d569",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### bias and eqm as functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b1e28675-ac34-4e50-9a47-d9f120105c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.007852477622572351, 0.01089015107255431)\n",
      "(0.016104817404162645, 0.0471181529039052)\n"
     ]
    }
   ],
   "source": [
    "array1 = np.array(sample_parameters)  \n",
    "\n",
    "def bias(theta, array1):\n",
    "    alpha = theta[0]\n",
    "    beta = theta[1]\n",
    "    bias_alpha = np.mean(array1[:,0]) - alpha\n",
    "    bias_beta = np.mean(array1[:,1]) - beta\n",
    "    return bias_alpha, bias_beta\n",
    "\n",
    "def EQM(theta, arrray1):\n",
    "    alpha = theta[0]\n",
    "    beta = theta[1]\n",
    "    eqm_alpha = np.mean( (array1[:,0] - alpha)**2 )\n",
    "    eqm_beta = np.mean( (array1[:,1] - beta)**2 )\n",
    "    return eqm_alpha, eqm_beta\n",
    "\n",
    "print(bias([3,5],array1))\n",
    "print(EQM([3,5],array1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
